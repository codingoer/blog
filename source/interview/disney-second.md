---
title: Disney Second
date: 2023-02-27 16:00:00
comments: false
sidebar: false
---

## 自我介绍

Hello everyone. My name is LiuQiang. I come from Hegang City, Heilongjiang province. I graduated {% label warning@ /ˈɡrædʒueɪtɪd/ %} from Harbin university, majoring in software engineering {% label warning@ /ˌendʒɪˈnɪrɪŋ/ %}. And graduated in 2016 {% label warning@ tow thousand and sixteen %}. After graduation {% label warning@ /ˌɡrædʒuˈeɪʃ(ə)n/ %}, I came to ShangHai. I have been working for more than six years now, as a Java development engineer. In order to develop better, I went to the Monster Charge in March 2021 {% label warning@ tow thousand and twenty one %}, and it has been until now. I am a cheerful and optimistic person. In my spare time, I like playing basketball and I also like riding bikes. Thank you for this oppotunity for interview. Thank you all !

Sorry, I'm a little nervous {%label warning @ /ˈnɜːrvəs/ %}. Let me say it again

Can you repeat that ？ I beg your pardon ?

## 系统架构 - 通用

{% note danger %}
1. 说明作用是什么？比如网关的作用、BFF的作用
2. 使用哪些技术点？为了解决什么问题
3. 抓住重点，原因是什么？为什么？怎么做的
{% endnote %}

### BFF之前

![20230226235705](https://image.codingoer.top/blog/20230226235705.png)

访问端包括APP、PC、小程序，用户请求依次经过WAF防火墙，Nginx负载均衡，API网关层。然后到达BFF层，BFF层调用各个领域Service完成用户相关操作。

1. 使用Nginx能够对Http做分流策略，承担**高负载**压力，
2. API网关对接流量的入口，可以对HTTP请求做**限流**，身份验证，配置黑白名单等。根据业务领域划分了多个网关，对应多个BFF，在流量很高时，将流量进行分流。
3. BFF的作用就是，完成接口聚合，屏蔽后端实现细节，保证接口规范，起到串联前后端的作用。作为流量的入口，BFF使用`sentinal`做限流，根据业务场景合并接口请求。同时针对热点接口做{% label primary@redis缓存 %}，使用{% label primary@多线程 %}的方式调用各个领域微服务完成接口聚合。针对一些耗时接口采用异步的方式提供给前端，前端进行轮训。BFF通过RPC或者Fegin的方式调用各个service。

API网关关键词：HTTP限流、鉴权
BFF关键词：限流、异步、合并请求、Redis缓存、接口聚合、屏蔽后端细节、接口规范。

### Service

![20230227002407](https://image.codingoer.top/blog/20230227002407.png)

基础服务也就是service负责具体业务实现，下层对接一些公共服务、数据库、缓存、ES等，上层承接BFF的请求。服务之间相互依赖相关调用。

1. 各个service之间的调用会设置超时时间和熔断，防止服务崩溃。当发生熔断时会返回一些mock数据。
2. 针对具体业务场景，会通过MQ的方式来实现服务之间的解耦，增加系统的吞吐量。
3. 在service中，针对耗时的接口采用异步的方式，并配合使用多线程来加快服务响应。
4. 针对一些常用配置做JVM缓存或Redis缓存。对节点接口做缓存。
5. 耗时，处理复杂，实时性不高的场景可以使用定时任务、延迟队列、

Service关键词：熔断、解耦、缓存、异步。

### 基础组件

![20230227004630](https://image.codingoer.top/blog/20230227004630.png)

1. MySQL读写分离，针对数据量大的场景做分库分表。核心流程走写库，一般查询走读库。
2. APP、PC列表查询走ES。MySQL达到一定的数据量的时候出现瓶颈

## 系统架构 - Enmonster

{% note danger %}
1. 我负责了那些功能模块？先概括到具体、从总到细，逻辑要清晰
2. 这些功能点使用了哪些技术？解决了什么问题？
3. 业务背景是什么？调理清晰的讲出来
4. 讲的细致
{% endnote %}

各个service之间的调用是通过Fegin来实现的，使用eruka作为注册中心。使用apollo作为配置中心。

### TOB业务


### TOC业务

我主要负责订单中心，包括下单、订单状态流转、订单查询等。

![20230228015209](https://image.codingoer.top/blog/20230228015209.png)

{% note info %}
{% label primary@多个网关和多个BFF的作用 %}

为了避免小程序BFF的慢接口把小程序支付宝/微信的网关线程池打满，导致小程序支付宝BFF/微信BFF的请求失败，用户无法下单。提供一个单独的APA网关，将其从下单链路中剥离出来，小程序辅助BFF的接口均走该网关
{% endnote %}

- 下单

首先构建下单上下文，基础信息校验，获取`分布式锁`并进入订单下单主流程：

1. 创建订单前核心校验，未完结订单异步取消、进行算价
2. 同步保存订单主信息，异步保存订单次要信息。
3. 如果有担保凭证则弹宝，加分布式锁（防止订单取消，同时弹宝）
4. 支付申请、下单后处理

订单的ID通过分布式ID服务生成，使用雪花算法，单个Bean支持每秒最多1024个id.对于生成的id是64个bit位的数据。分布式ID生成服务部署5台机器。一秒最多可生成5000个订单。每日订单量300万，历史最高500万。针对这么大的数据量，订单系统落库时使用ShardingJdbc进行分库。对历史订单进行了分区。

- 订单状态流转

查询订单通过MySQL的for update加锁，然后判断状态，更新订单状态。

- 订单查询

订单查询分为后台查询，用户侧查询。订单列表和订单详情。

后台查询订单数据是通关订单数据同步服务，同步到ES中，在数据同步服务中使用了阿里云的DTS组件。原理合canal一样，监听binlog，将变更转发到Kafka中。
用户侧查询订单使用Redis缓存，因为用户会频繁查看订单。比如会缓存用户第一页的订单列表，如果缓存没有的话查询数据库。比如用户第一页的订单列表都是查询缓存的。

### 性能指标

- 机器数（日常）：

网关：每个网关是3台机器
BFF：每个BFF是3-4台
分布式ID生成服务：5台     
下单服务：5台
其他服务：2-3台

- QPS：

网关：每个网关平均500，历史最高1千，总的QPS大约就是4千到五千。
BFF：每个平均500
分布式ID生成服务：平均500
下单服务：平均500

## 系统架构 - 1haitao

{% note danger %}
1. 我负责了那些功能模块？背景是什么？
2. 先概括到具体、从总到细，逻辑要清晰
3. 这些功能点使用了哪些技术？
{% endnote %}

各个service之间的调用是通过gRPC来实现的，使用zookeeper作为服务的注册中心。采用SpringCloud config作为service的配置中心。

我主要负责爬虫、商品库、购物车、物流、BFF等微服务的开发与维护。

### 爬虫

![20230227010623](https://image.codingoer.top/blog/20230227010623.png)

因为是海淘业务，所以商品是经过爬虫爬取国外网站后入库的。爬虫分为前置节点、执行节点、下发节点三个模块。

- 下发节点

下发节点负责处理任务逻辑，使用gRPC异步调用执行节点。Redis缓存一层，对爬取后的结果也会做Redis缓存，会设置缓存时间，命中缓存时直接返回。下发节点作为爬虫服务的入口。商品服务调用爬虫服务。

- 执行节点

执行节点用来执行任务，下发节点调用执行节点。获取可执行的前置节点列表，同样通过gRPC异步调用前置节点。执行节点会对前置节点进行动态更新，选择最优的前置节点。

- 前置节点

前置节点部署在国内外50多台机器上，作为爬虫的最前端。使用多线程来爬取商品。前置节点爬取完商品后，对数据进行校验，加工处理。Redis缓存结果。

### 商品库&搜索

![20230227011413](https://image.codingoer.top/blog/20230227011413.png)

在商品服务中可以通过定时任务Job批量爬取商品入库，也支持对已有商品的更新。商品更新会调用爬虫，然后更新MySQL，最后更新ES。入库或更新均采用多线程异步的方式。商品表包含主表和其他属性表，按需写入和查询，降低复杂度，提高查询效率。


因为MySQL不支持复杂的搜索，在数据量比较大的时候会出现一些瓶颈。使用canal订阅MySQL binlog，经过RocketMQ的转发同步到ES中。
在ES中维护了活动、商品、品牌等数据。支持普通搜索、品牌搜索、聚合搜索、权重搜索等。预留刷索引的接口，可以对全量数据进行刷新，当ES索引结构发生变化时对索引进行重建。

### 其他项目

- 购物车

功能点包括：添加购物车、删除购物车、购物车列表、价格计算（运费、促销、税费、重量）等，简历中写到购物车解构，主要是这部分逻辑复杂，接口升级的时候做了新老版本兼容。针对各个模块进行拆分，从业务流程中独立出来，提高代码的可维护性，可方便单元测试。

- BFF

主要是对接口封装。统一规划各个页面模型和二级页面的跳转。使用了缓存、多线程协同、异步的方式提高响应速度，引入限流工具。因为在流量大的时候，保护下游服务的稳定。

- 物流

物流轨迹使用MongoDB存储，订阅第三方物流信息，回调处理。

### 性能指标

- QPS：平时2000.高峰期5000左右。 平均RT：200ms
- 服务器：8台  针对活动期准备：扩容机器一倍
- 用户量：20w

## 模拟问答

### 如何达到xxxQPS

1. 前端资源CND静态化、资源预加载，预热
2. 多线程，线程同步，异步化
3. 多级缓存和本地缓存
4. MQ削峰和解耦
5. 熔断、限流、降级
6. 读写分离，分库分表
7. 应用集群部署
8. 系统分层设计，分布式
9. ES搜索

### 应对活动期

根据各个系统的流量进行分析，单台机器可以承载的最大并发量，预估活动时的范围，加机器。

### 缓存

1. 本地缓存与Redis的缓存的区别？
使用Redis缓存有网络开销，Redis是分布式缓存，有并发竞争问题。容易出现缓存雪崩等问题。

2. 缓存与数据库一致性问题？
旁路缓存模式、读写穿透模式、异步缓存写入模式（写缓存加锁）最终一致性和强一致性

3. 缓存雪崩，大量Key失效？
设置缓存过期时间的时候加上随机值，防止大量key在同一时间同时失效，造成缓存雪崩的问题。

### MQ

1. 消息堆积原因和处理

在消息堆积时，会有钉钉告警。一般出现消息堆积，主要是客户端本地消费过程中，由于消费耗时过长或消费并发度较小等原因，导致客户端消费能力不足，出现消息堆积的问题。登录RocketMQ控制台查看消息堆积的数量，是否在可接受的范围。

- 紧急扩容
- 分析具体业务，是否刷数据
- 代码层面，一般不会

最后，如果消息堆积已经影响到了业务运行，堆积的消息可以跳过不消费，可以通过重置消费位点的方式，从最新位点开始消费，快速恢复业务。
实际问题：用户无法再列表查看他创建的单子

2. 消费失败

- 直接抛异常让RocketMQ进行重新消费，RETRY Topic，重试最大16次进入死信队列。
- 发送告警，代码中进行重试一定次数

3. 消息幂等性

对于同一操作发起的一次请求或者多次请求的结果是一致的。当出现消费者对某条消息重复消费的情况时，重复消费的结果与消费一次的结果是相同的，并且多次消费并未对业务系统产生任何负面影响。

- Redis原子操作
- 乐观锁
- try catch捕获异常，发送告警，手动重试

### MySQL

1. MySQL分区

MySQL数据库中的数据是以文件的形式存储在磁盘介质上，如果一张表的数据量太大的话，**查找数据就会变得很慢**。这个时候可以利用MySQL的分区功能。**在物理上分割成许多个小块**，这样做的话，我们查找一条数据时就不用全部查找了，只要知道这条数据在哪一块，然后在那一块找就行了。这些区块可以在同一个磁盘上，也可以在不同的磁盘上。
最常见的就是按照时间进行分区。（RANGE分区）

分区最大的优点就是可以非常高效的进行历史数据的清理。突破磁盘的读写能力。

- 分区的优点

存储更多数据、优化查询（`where`子句中包含分区条件时，只扫描一个分区）、不要的数据的有关分区快速删除、跨越多个磁盘分散查询。

- 分区的缺点

分区无法使用外检约束、一个表最多只能有 1024 个分区

![20230301002033](https://image.codingoer.top/blog/20230301002033.png)

2. MySQL分表

分表就是把一张超大的数据表，拆分成多个极小的表。大表带来的影响：降低性能、对应的索引大，查询效率降低。
水平分表的功能或许可以用更加便捷的分区来替代，但是{% label info @垂直分表 %}的功能，分区却无法替代。

分表和分区的区别

![20230301003104](https://image.codingoer.top/blog/20230301003104.png)

分表的类型：水平分表、垂直分表。

3. MySQL分库

分库同样是为了应对超大数据带来的巨大的IO需求，如果不拆库，那么单库所能支持的吞吐能力和磁盘空间，就会成为制衡业务发展的瓶颈。
分库的主要目的是为突破单节点数据库服务器的I/O能力限制，解决数据库水平扩展性问题。

分库的作用：将一个库分成多个库，并在多个服务器上部署，就可以突破单服务器的性能瓶颈，这是分库必要性的最主要原因。

分库的类型：水平分库、垂直分库。

4. MySQL InnoDB 排他锁

```sql
select .... for update
```

排他锁的申请前提：没有线程对该结果集中的任何行数据使用排他锁或共享锁，否则申请会阻塞。且必须在事务块中才能生效。
在进行事务操作时，通过`for update`语句，MySQL会对查询结果集中每行数据都添加排他锁，其他线程对该记录的更新与删除操作都会阻塞。排他锁包含行锁、表锁。

MySQL的行锁是针对索引加的锁，否则，InnoDB将使用表锁。

### gRPC

1. 异步调用的优缺点

- 服务解耦
- 提升性能，CPU资源大量浪费在阻塞等待上
- 没有强依赖性
- 流量削峰

## 复杂系统化解

### QQ订阅推送场景

[原文链接](https://juejin.cn/post/7197955458961965117)，先概括，再细分。

### 场景

QQ服务了大量的移动互联网用户，订阅提醒功能超大流量。

1. 《使用召唤》手游早上10点发布，提醒预约用户领取礼包。
2. 春节刷一刷领红包，晚上8:05开始，提醒用户订阅参与。

关键词：高并发、海量用户、推送消息的可靠性、推送的高效性

### 数据存储

- 业务方创建的任务数据。包含任务的提醒时间和提醒内容

任务数据可靠性要求高，不需要快速存取，使用MySQL即可

- 用户订阅生成的订阅数据（千万以上）

订阅列表数据需要频繁读写，且推送触发时对于存取效率要求较高，考虑使用内存型数据库。

![20230301023430](https://image.codingoer.top/blog/20230301023430.png)

```bash
SADD key
SPOP key
```

- 活动被订阅的数据，空间换时间，方便统计

### 推拉结合

消息推送模式主要分为拉取和推送两种，通过组合可以形成如下表呈现的几种模式。

![20230301022711](https://image.codingoer.top/blog/20230301022711.jpg)

允许部分用户提前拉取到任务，未拉取的走推送。离线用户异步拉取，在线用户主动推送。

### 触发器

采用延迟队列，即是基于`Redis sorted set` 实现。增加了本地数据库轮询。
假如外部组件通用计时器没有准时回调，本地轮询会在延迟3秒后将还未触发的任务进行触发。

### 调度器/执行器

当多个千万级别的推送任务在同一时间触发时，推送量是很可观的。调度器来控制每一秒钟的推送量。调度器必须是分布式，以避免单点服务。

`Redis INCR`命令计数，记录当前秒钟的请求量，如果累加的结果没有超过配置值，则继续累加。

### 消息队列

- 将任务调度和任务执行解耦

- 异步化，保证调度服务的高效执行

- 借助消息队列实现任务的可靠消费

- 将瞬时高并发的任务量打散执行，达到削峰的作用。


## 高并发系统设计

### 前端层面

使用CDN加速静态资源访问。CDN可以让用户就近获取所需内容。对页面做静态化处理，减少访问服务端的请求。

### 系统设计层面

1. 微服务拆分
其实就是把一个单体的应用，按功能单一性，拆分为多个服务模块。比如一个电商系统，拆分为用户系统、订单系统、商品系统等等。
按照功能划分，比如网关、BFF、应用、公共服务等等。

2. 分而治之，横向扩容
采用分布式部署的方式，部署多台服务器，把流量分流开，让每个服务器都承担一部分的并发和流量。如果一台机器挂了不会影响主业务流程，保证系统的高可用性。

3. 负载均衡

### 数据层面

1. 分库分表

当业务量暴增的话，MySQL单机磁盘容量会撑爆。需要考虑拆分为多个数据库，来抗住高并发的毒打。一般千万级别数据量，就需要分表，每个表的数据量少一点，提升SQL查询性能。

2. 主从分离

如果所有的查询请求，都走主库的话，主库肯定扛不住，因为查询请求量是非常非常大的。因此一般都要求做主从分离。
实时性要求不高的读请求，都去读从库，写的请求或者实时性要求高的请求，才走主库。

3. 池化技术

数据库连接数可能成为瓶颈，因为连接数是有限的。

4. ElasticSearch

### 服务层面

1. 熔断降级

熔断降级是保护系统的一种手段。当前互联网系统一般都是分布式部署的。而分布式系统中偶尔会出现某个基础服务不可用，最终导致整个系统不可用的情况, 这种现象被称为服务雪崩效应。

为了应对服务雪崩, 常见的做法是熔断和降级。最简单是加开关控制，当下游系统出问题时，开关打开降级，不再调用下游系统

2. 限流

因为系统的CPU、网络带宽、内存、线程等资源都是有限的。限流就是控制网络接口发送或接收请求的速率，

3. 消息队列

MQ削峰和解耦

### 缓存

常用的缓存包括：Redis缓存，JVM本地缓存。比如Redis缓存来说，它单机就能轻轻松松应对几万的并发，你读场景的业务，可以用缓存来抗高并发。

### 常规手段

1. 批量思想
2. 多线程、线程同步、异步化
3. 拒绝阻塞等待
4. 加锁的粒度
5. SQL语句、索引
6. 合并IO



